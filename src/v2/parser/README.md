running getpdfs.py will pull a list of URL's to look at from the DB, and then pull 100% of the a tags with href atribs.  It will then try and PDF decode each link, and if it is bad it will flag it as such in the DB.  Once it comes across a 'good' pdf file, it will convert it to text, remove all punctuation, use NLTK to generate a histogram of work frequency, and then put the full pdf text + the histogram data into the database.  It also pulls the publish date from the PDF text and attempts to match a name of an organization to the header information.  
